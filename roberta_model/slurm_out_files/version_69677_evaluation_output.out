Sat Mar  4 11:43:15 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.60.11    Driver Version: 525.60.11    CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            Off  | 00000000:00:0A.0 Off |                    0 |
| N/A   38C    P8     9W /  70W |      2MiB / 15360MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
 11:43:15 up 2 days, 21:56,  1 user,  load average: 1.14, 1.21, 1.19
Checkpoint: /vol/bitbucket/es1519/NLPClassification_01/roberta_model/saved/ROBERTA/lightning_logs/version_69677/checkpoints/epoch=0-step=122_converted.ckpt
Test File: /vol/bitbucket/es1519/NLPClassification_01/roberta_model/DontPatronizeMe/csv_files/dontpatronizeme_pcl_test.csv
Config: /vol/bitbucket/es1519/NLPClassification_01/roberta_model/configs/RoBERTa_config.json
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/vol/bitbucket/es1519/myvenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Batch size: 10
Dataset: /vol/bitbucket/es1519/NLPClassification_01/roberta_model/DontPatronizeMe/csv_files/dontpatronizeme_pcl_test.csv
{'name': 'ROBERTA', 'n_gpu': 1, 'batch_size': 10, 'accumulate_grad_batches': 3, 'num_main_classes': 1, 'loss_weight': 0.75, 'arch': {'type': 'ROBERTA', 'args': {'num_classes': 1, 'model_type': 'roberta-base', 'model_name': 'RobertaForSequenceClassification', 'tokenizer_name': 'RobertaTokenizer'}}, 'dataset': {'type': 'DontPatronizeMePCL', 'args': {'train_csv_file': '/vol/bitbucket/es1519/NLPClassification_01/roberta_model/DontPatronizeMe/csv_files/dontpatronizeme_pcl_train.csv', 'val_csv_file': '/vol/bitbucket/es1519/NLPClassification_01/roberta_model/DontPatronizeMe/csv_files/dontpatronizeme_pcl_val.csv', 'test_csv_file': '/vol/bitbucket/es1519/NLPClassification_01/roberta_model/DontPatronizeMe/csv_files/dontpatronizeme_pcl_test.csv', 'loss_weight': 0.75, 'classes': ['label']}}, 'optimizer': {'type': 'Adam', 'args': {'lr': 3e-05, 'weight_decay': 3e-06, 'amsgrad': True}}, 'gpus': 'cuda:0'}
Loading data: mode=TEST
<src.data_loaders.DontPatronizeMePCL object at 0x7fb623100c40>
<torch.utils.data.dataloader.DataLoader object at 0x7fb6231df520>
  0%|          | 0/158 [00:00<?, ?it/s]  1%|          | 1/158 [00:02<07:28,  2.85s/it]  1%|▏         | 2/158 [00:02<03:12,  1.23s/it]  3%|▎         | 4/158 [00:03<01:15,  2.03it/s]  4%|▍         | 6/158 [00:03<00:44,  3.43it/s]  5%|▌         | 8/158 [00:03<00:29,  5.06it/s]  6%|▋         | 10/158 [00:03<00:21,  6.86it/s]  8%|▊         | 12/158 [00:03<00:16,  8.79it/s]  9%|▉         | 14/158 [00:03<00:14, 10.02it/s] 10%|█         | 16/158 [00:03<00:12, 11.11it/s] 11%|█▏        | 18/158 [00:03<00:10, 12.85it/s] 13%|█▎        | 20/158 [00:04<00:11, 12.26it/s] 14%|█▍        | 22/158 [00:04<00:14,  9.39it/s] 15%|█▌        | 24/158 [00:04<00:12, 11.02it/s] 16%|█▋        | 26/158 [00:04<00:10, 12.24it/s] 18%|█▊        | 28/158 [00:04<00:10, 12.30it/s] 19%|█▉        | 30/158 [00:04<00:09, 13.43it/s] 20%|██        | 32/158 [00:05<00:08, 14.48it/s] 22%|██▏       | 34/158 [00:05<00:08, 15.49it/s] 23%|██▎       | 37/158 [00:05<00:06, 17.99it/s] 25%|██▌       | 40/158 [00:05<00:06, 18.32it/s] 27%|██▋       | 42/158 [00:05<00:06, 17.92it/s] 28%|██▊       | 44/158 [00:05<00:06, 17.50it/s] 29%|██▉       | 46/158 [00:05<00:06, 17.40it/s] 30%|███       | 48/158 [00:05<00:06, 17.16it/s] 32%|███▏      | 50/158 [00:06<00:06, 16.61it/s] 33%|███▎      | 52/158 [00:06<00:06, 16.56it/s] 34%|███▍      | 54/158 [00:06<00:06, 15.91it/s] 35%|███▌      | 56/158 [00:06<00:06, 15.95it/s] 37%|███▋      | 58/158 [00:06<00:06, 14.63it/s] 38%|███▊      | 60/158 [00:06<00:06, 15.63it/s] 40%|███▉      | 63/158 [00:06<00:05, 17.46it/s] 41%|████      | 65/158 [00:06<00:05, 15.94it/s] 42%|████▏     | 67/158 [00:07<00:06, 14.61it/s] 44%|████▎     | 69/158 [00:07<00:05, 15.64it/s] 46%|████▌     | 72/158 [00:07<00:05, 16.71it/s] 47%|████▋     | 74/158 [00:07<00:05, 15.77it/s] 48%|████▊     | 76/158 [00:07<00:05, 15.55it/s] 49%|████▉     | 78/158 [00:07<00:05, 15.33it/s] 51%|█████     | 80/158 [00:07<00:05, 14.99it/s] 53%|█████▎    | 83/158 [00:08<00:04, 16.63it/s] 54%|█████▍    | 85/158 [00:08<00:04, 16.82it/s] 56%|█████▌    | 88/158 [00:08<00:04, 17.08it/s] 57%|█████▋    | 90/158 [00:08<00:04, 16.30it/s] 58%|█████▊    | 92/158 [00:08<00:04, 16.32it/s] 59%|█████▉    | 94/158 [00:08<00:03, 16.65it/s] 61%|██████    | 96/158 [00:08<00:03, 16.56it/s] 62%|██████▏   | 98/158 [00:09<00:03, 17.40it/s] 63%|██████▎   | 100/158 [00:09<00:03, 17.05it/s] 65%|██████▍   | 102/158 [00:09<00:03, 16.74it/s] 66%|██████▋   | 105/158 [00:09<00:03, 17.50it/s] 68%|██████▊   | 107/158 [00:09<00:02, 17.78it/s] 70%|██████▉   | 110/158 [00:09<00:02, 18.38it/s] 71%|███████   | 112/158 [00:09<00:02, 17.42it/s] 72%|███████▏  | 114/158 [00:09<00:02, 17.73it/s] 73%|███████▎  | 116/158 [00:10<00:02, 16.37it/s] 75%|███████▌  | 119/158 [00:10<00:02, 17.49it/s] 77%|███████▋  | 121/158 [00:10<00:02, 17.89it/s] 78%|███████▊  | 123/158 [00:10<00:02, 17.26it/s] 79%|███████▉  | 125/158 [00:10<00:02, 16.37it/s] 81%|████████  | 128/158 [00:10<00:01, 17.82it/s] 82%|████████▏ | 130/158 [00:10<00:01, 17.46it/s] 84%|████████▎ | 132/158 [00:10<00:01, 16.43it/s] 85%|████████▍ | 134/158 [00:11<00:01, 15.37it/s] 86%|████████▌ | 136/158 [00:11<00:01, 16.28it/s] 87%|████████▋ | 138/158 [00:11<00:01, 16.26it/s] 89%|████████▊ | 140/158 [00:11<00:01, 16.64it/s] 90%|████████▉ | 142/158 [00:11<00:00, 17.34it/s] 91%|█████████ | 144/158 [00:11<00:00, 17.15it/s] 92%|█████████▏| 146/158 [00:11<00:00, 15.74it/s] 94%|█████████▍| 149/158 [00:12<00:00, 16.67it/s] 96%|█████████▌| 152/158 [00:12<00:00, 17.80it/s] 97%|█████████▋| 154/158 [00:12<00:00, 17.78it/s] 99%|█████████▊| 156/158 [00:12<00:00, 17.95it/s]100%|██████████| 158/158 [00:12<00:00, 12.53it/s]
/vol/bitbucket/es1519/myvenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
[[0]
 [0]
 [0]
 ...
 [0]
 [0]
 [0]]
[[0]
 [0]
 [0]
 ...
 [0]
 [1]
 [0]]
Accuracy: 0.9236155315085932
Precision: 0.8530656500439012
Recall: 0.9236155315085932
F1 score: 0.8869398651349892
[2637, 6488, 8010, 2559, 5455, 9580, 3142, 2885, 6624, 3372, 9957, 4519, 14, 5643, 1549, 4683, 5172, 623, 7455, 284, 2301, 1116, 9379, 6120, 2036, 6812, 4082, 4149, 9663, 425, 5186, 2835, 8306, 9071, 761, 6805, 5384, 7781, 8530, 7483, 6397, 6333, 8017, 10107, 717, 7962, 7244, 4855, 2436, 7122, 2410, 3471, 3257, 4401, 7310, 139, 4085, 5411, 1134, 2921, 9716, 6999, 2156, 4248, 10176, 5940, 8970, 8235, 1372, 1934, 3264, 3843, 2433, 8310, 4938, 8376, 4615, 1183, 8492, 7457, 6740, 1424, 9274, 10305, 8473, 436, 9781, 2015, 8641, 9595, 6601, 5225, 1217, 3709, 4881, 3545, 1607, 1696, 5232, 347, 8742, 3994, 627, 4539, 3013, 898, 2268, 8844, 9403, 10401, 7262, 4906, 8749, 6427, 4221, 5600, 4151, 8533, 10093, 1227, 8079, 3647, 8222, 596, 7391, 8934, 3340, 3566, 8962, 1472, 3089, 9860, 9369, 7373, 7252, 6640, 1566, 4641, 8248, 3615, 9964, 167, 8948, 9120, 5439, 6770, 3827, 5627, 2153, 9035, 5837, 582, 7777, 8873, 4250, 4446, 1045, 1706, 6378, 3423, 6377, 6355, 8028, 5050, 4180, 3657, 3217, 5459, 7695, 2449, 2296, 710, 7622, 2369, 801, 9821, 6568, 7906, 4899, 3698, 2464, 9973, 2873, 6685, 3202, 7054, 7494, 6044, 3389, 530, 453, 6984, 10235, 3449, 6126, 4363, 5030, 3352, 4613, 2041, 5089, 7419, 3339, 4682, 5080, 2389, 8517, 4706, 17, 1415, 1203, 2060, 3760, 561, 6326, 9335, 6735, 2892, 6465, 9354, 238, 9339, 9680, 3589, 1908, 4092, 5387, 4678, 2614, 2681, 7713, 6839, 6179, 9344, 7037, 2355, 7507, 1791, 2764, 3705, 2078, 391, 3575, 8159, 6506, 2207, 9793, 4456, 7248, 3955, 3989, 6909, 2569, 5856, 4372, 5655, 4365, 8172, 6947, 3775, 5318, 6880, 4464, 2475, 1521, 262, 8127, 1984, 9525, 3159, 120, 5590, 7497, 6730, 8072, 6288, 2289, 9135, 8670, 6742, 2965, 7035, 237, 5774, 10281, 7840, 7219, 9513, 6028, 9205, 6336, 6941, 468, 3254, 6385, 4999, 6324, 505, 2903, 3863, 23, 3513, 2695, 4807, 8301, 7064, 7484, 1779, 3889, 9349, 3329, 9544, 736, 3464, 83, 5693, 1556, 2382, 7476, 3390, 3037, 5896, 10423, 3247, 3747, 4015, 9447, 10340, 124, 7912, 880, 10368, 8281, 4078, 9337, 1481, 1073, 7619, 5081, 7285, 4005, 4466, 3236, 6748, 1765, 9434, 7214, 3428, 7276, 7345, 3478, 2152, 5350, 6772, 5651, 7160, 5377, 3516, 7727, 158, 9115, 1890, 536, 4918, 3170, 6518, 6504, 2850, 1989, 400, 702, 9479, 10018, 353, 8896, 3898, 116, 1530, 9701, 1625, 68, 6143, 9276, 6034, 609, 7683, 3252, 9181, 885, 3135, 3750, 6856, 1638, 2139, 7658, 2944, 1732, 10078, 7823, 7875, 1842, 8234, 10116, 9432, 8042, 8504, 4074, 973, 6663, 6371, 9549, 798, 8730, 3646, 1867, 10293, 9086, 2669, 9997, 1230, 4468, 5699, 471, 442, 6109, 1749, 1320, 2781, 8956, 7901, 5967, 10029, 3349, 7178, 8353, 2356, 9742, 16, 5137, 4444, 648, 10148, 3524, 4502, 9081, 4114, 8562, 9719, 9814, 6581, 6642, 5707, 2912, 8616, 5924, 1808, 4693, 8237, 3641, 3065, 3070, 4732, 3283, 9791, 1434, 8564, 7462, 4697, 3455, 8238, 7523, 5522, 7311, 8153, 8646, 9808, 2059, 4949, 2119, 7689, 8229, 2777, 10466, 6524, 3857, 7478, 9792, 1281, 8532, 9206, 2800, 1895, 5891, 9110, 184, 8082, 2562, 2813, 1721, 4995, 6511, 3399, 6882, 7574, 7664, 6800, 5017, 2249, 6637, 1090, 5906, 6638, 8271, 1750, 5112, 3523, 4562, 10178, 6899, 3003, 9889, 9925, 2087, 3770, 6376, 7148, 5951, 7739, 8233, 748, 5027, 8266, 7143, 8118, 4537, 4433, 8283, 115, 4061, 3673, 3100, 9427, 729, 4708, 3752, 10307, 5301, 8653, 7138, 10467, 9613, 4571, 3686, 1575, 4833, 9937, 295, 6522, 3116, 1898, 3642, 5851, 1480, 3265, 5362, 2933, 10453, 8632, 6038, 2802, 8796, 4920, 9641, 4752, 5668, 3158, 8698, 1123, 10461, 4046, 6792, 7187, 10316, 4823, 9681, 9656, 2644, 6457, 850, 7367, 7207, 2829, 9314, 9275, 9075, 3263, 3801, 3097, 9865, 9508, 10037, 2659, 8202, 10102, 9401, 3947, 9625, 9459, 8508, 1166, 8570, 2384, 835, 1339, 9333, 3873, 3841, 6265, 10226, 2928, 3213, 7368, 8451, 2931, 3269, 2129, 8323, 8167, 8296, 8457, 7046, 5636, 1615, 9850, 610, 5161, 6558, 7081, 6040, 8131, 5309, 9741, 8354, 9400, 1945, 7169, 7191, 8575, 6589, 2104, 5619, 1239, 6762, 8978, 31, 6895, 9830, 535, 6003, 6598, 38, 5188, 3720, 2920, 3448, 9283, 2062, 3181, 6650, 7693, 1804, 2926, 3525, 4946, 10455, 6759, 7177, 5465, 804, 2467, 10073, 9950, 6686, 3337, 3774, 7492, 130, 5386, 8333, 5502, 2493, 10016, 1901, 6332, 3878, 5074, 9179, 10216, 1111, 8840, 1955, 533, 9372, 1879, 5849, 6632, 1515, 5528, 5963, 3631, 10432, 7327, 528, 6098, 2197, 10407, 140, 7025, 2584, 10043, 3327, 1942, 6557, 4915, 9898, 7312, 5810, 3933, 3871, 10237, 7681, 1351, 10075, 7843, 8505, 3961, 1691, 6662, 6609, 9542, 6527, 8071, 362, 6985, 6819, 2962, 4332, 10312, 3807, 5691, 2285, 6535, 3006, 7680, 1099, 7910, 10241, 6481, 6946, 5787, 7182, 8318, 3033, 4224, 7066, 3416, 1835, 10074, 9026, 4951, 944, 2708, 5438, 1300, 4850, 5427, 7539, 6543, 5554, 9443, 399, 4357, 9203, 10414, 8026, 9926, 4570, 3995, 5654, 8495, 4934, 8668, 8942, 1692, 4901, 10222, 1578, 10182, 2549, 10365, 855, 5778, 7456, 5199, 3940, 8696, 7144, 800, 6464, 6788, 7282, 7894, 2678, 853, 1068, 357, 6423, 8396, 8204, 9919, 6689, 10412, 4091, 5920, 6515, 5817, 5023, 8799, 2680, 6221, 3771, 4408, 7110, 7284, 2518, 8549, 8969, 480, 6585, 2963, 4088, 9914, 4287, 6827, 6372, 8868, 2483, 5280, 7003, 9084, 4115, 10001, 6672, 3325, 8240, 4785, 8139, 1189, 699, 3846, 5328, 10177, 6843, 10463, 4651, 8031, 8426, 7108, 6779, 2071, 6567, 9778, 6603, 2635, 6149, 9412, 4264, 2534, 8537, 1547, 10104, 5115, 9163, 296, 4808, 7758, 3480, 4185, 8347, 1979, 5887, 2393, 809, 3320, 5857, 7764, 6169, 985, 3438, 1990, 7522, 2072, 56, 8123, 4908, 6639, 8777, 2914, 3004, 4877, 7628, 8317, 5145, 3055, 3804, 1911, 7009, 5721, 125, 28, 7865, 4701, 3830, 1618, 3864, 7451, 8056, 4880, 479, 10095, 8058, 1284, 266, 672, 8555, 9579, 4517, 6419, 4958, 5283, 831, 6545, 152, 4556, 6867, 1645, 7044, 7318, 10051, 696, 5768, 5800, 4894, 10385, 10464, 6876, 6755, 6711, 2690, 5472, 5361, 8035, 7242, 5536, 9465, 703, 10364, 5961, 10399, 9076, 6185, 2374, 1427, 8447, 6010, 6107, 4991, 1565, 7889, 483, 6387, 7868, 5369, 1544, 5234, 981, 3723, 5160, 7180, 1186, 10111, 5743, 7587, 2917, 2142, 3190, 292, 2743, 10327, 435, 5457, 3983, 287, 5308, 7424, 6493, 6241, 9285, 1573, 4231, 5388, 7514, 7264, 1015, 7724, 10027, 8110, 7334, 5520, 4024, 8245, 2158, 3322, 3654, 6308, 1837, 4617, 7101, 704, 1858, 7997, 7608, 5167, 245, 9523, 9608, 6013, 986, 9416, 7685, 6105, 1328, 10211, 9624, 3035, 2113, 1733, 1490, 8967, 6456, 6835, 1586, 4870, 1991, 8432, 10458, 5660, 6352, 9355, 4459, 3599, 5339, 8773, 3964, 2109, 8975, 5491, 4413, 2421, 7405, 1557, 5758, 1830, 2133, 2477, 3594, 4726, 1709, 277, 6658, 6647, 6954, 4432, 8526, 3684, 9309, 5888, 9097, 8029, 3674, 5124, 4086, 6803, 1650, 6676, 2707, 737, 5304, 10063, 5085, 7129, 6405, 1062, 4552, 6552, 6773, 6560, 4, 3938, 2552, 892, 4416, 5303, 8831, 6361, 5185, 2806, 6294, 5299, 4435, 4801, 4310, 5596, 6213, 402, 926, 10143, 10408, 7869, 2132, 3836, 9758, 7344, 8754, 9028, 4928, 7694, 5782, 9381, 2798, 5003, 7389, 3014, 3260, 8932, 4183, 1774, 2831, 4373, 937, 4940, 3415, 8785, 8054, 634, 1545, 4754, 1906, 3954, 9096, 8988, 3993, 2234, 1646, 3719, 2898, 5483, 2460, 176, 8762, 9430, 7058, 2381, 5696, 4473, 9975, 256, 8080, 4066, 3346, 3634, 6077, 861, 9399, 3029, 3612, 3064, 8709, 4646, 8941, 1314, 4093, 9252, 2185, 6114, 1233, 7142, 8272, 1720, 9078, 542, 3401, 8158, 1213, 3756, 3071, 10296, 5903, 9132, 2565, 8311, 5694, 3224, 3038, 8682, 5687, 4334, 1103, 3672, 2357, 2204, 4738, 9210, 3950, 8440, 8738, 6811, 9234, 2679, 2004, 5016, 7592, 3381, 1201, 526, 7393, 5750, 4522, 1101, 6388, 8008, 3582, 9621, 7594, 290, 3730, 5886, 138, 1767, 1896, 4130, 5934, 5368, 534, 4256, 8633, 3593, 5996, 5814, 3819, 3244, 4402, 2880, 3849, 9836, 8997, 4538, 7446, 5872, 9532, 5131, 4794, 8960, 5287, 7369, 3364, 10403, 4639, 4687, 6965, 3975, 708, 7715, 6617, 5753, 2528, 2128, 6830, 5187, 656, 778, 8421, 3261, 1398, 8299, 456, 6416, 7721, 4702, 8554, 4423, 25, 6599, 6666, 4125, 6240, 8850, 7677, 258, 7687, 1080, 5134, 4700, 5933, 1240, 1707, 5883, 8276, 5840, 4903, 7320, 8675, 5682, 9264, 6121, 10021, 6764, 3102, 2427, 6970, 4703, 4933, 6068, 6455, 9790, 5370, 8106, 2083, 3610, 3499, 7898, 2822, 10273, 4653, 683, 2243, 9528, 7435, 1504, 1060, 2013, 1722, 620, 9565, 8322, 4096, 8413, 121, 7819, 2199, 6629, 5697, 349, 6430, 8679, 4045, 2295, 6976, 5257, 7961, 345, 8644, 5749, 5690, 8287, 2465, 8221, 10334, 8579, 8636, 3597, 4974, 8681, 942, 3632, 4406, 5578, 6793, 5274, 2960, 9072, 7671, 2034, 9502, 3429, 9073, 5843, 3767, 9357, 3216, 1242, 6849, 10335, 4704, 6916, 2980, 3082, 946, 8560, 6903, 7860, 1383, 2583, 6691, 5417, 2237, 6060, 190, 7221, 7855, 8275, 785, 7798, 8415, 9939, 6074, 4925, 5820, 70, 7862, 484, 8052, 2431, 4484, 2916, 9546, 6337, 9738, 2642, 8904, 8032, 7974, 8105, 3960, 8712, 10363, 6551, 8130, 407, 3650, 3042, 8092, 3920, 8487, 1192, 6948, 3436, 8174, 7757, 6263, 9183, 9013, 4184, 1425, 9486, 2063, 3625, 3348, 7430, 8478, 10188, 5703, 2051, 1678, 8239, 3943, 2052, 2535, 172, 4932, 3288, 2592, 2108, 10076, 3489, 5612, 5799, 9348, 2232, 1769, 3746, 8382, 8722, 6893, 726, 6519, 2770, 7475, 8160, 5221, 10138, 670, 182, 4032, 5965, 8561, 2864, 9567, 5979, 4913, 3556, 7586, 7699, 5340, 4460, 5482, 1878, 9377, 9679, 10417, 4292, 5430, 1595, 3117, 698, 2516, 7956, 2200, 10344, 4269, 690, 1948, 1362, 276, 8892, 7437, 3023, 2170, 7564, 4856, 5210, 8516, 2677, 10284, 6510, 9421, 1329, 2580, 2420, 5191, 1659, 3018, 162, 8442, 1109, 3968, 3239, 66, 6661, 7679, 5437, 10469, 8252, 4676, 9397, 2979, 8003, 5884, 9043, 1036, 5973]
